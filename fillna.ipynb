{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fancyimpute\n",
      "  Downloading fancyimpute-0.7.0.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting knnimpute>=0.1.0 (from fancyimpute)\n",
      "  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from fancyimpute) (1.2.2)\n",
      "Collecting cvxpy (from fancyimpute)\n",
      "  Downloading cvxpy-1.4.2-cp39-cp39-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting cvxopt (from fancyimpute)\n",
      "  Downloading cvxopt-1.3.2-cp39-cp39-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: pytest in c:\\programdata\\anaconda3\\lib\\site-packages (from fancyimpute) (6.2.4)\n",
      "Requirement already satisfied: nose in c:\\programdata\\anaconda3\\lib\\site-packages (from fancyimpute) (1.3.7)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.10 in c:\\users\\kcs\\appdata\\roaming\\python\\python39\\site-packages (from knnimpute>=0.1.0->fancyimpute) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.7.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24.2->fancyimpute) (2.2.0)\n",
      "Collecting osqp>=0.6.2 (from cvxpy->fancyimpute)\n",
      "  Downloading osqp-0.6.5-cp39-cp39-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting ecos>=2 (from cvxpy->fancyimpute)\n",
      "  Downloading ecos-2.0.13-cp39-cp39-win_amd64.whl.metadata (8.2 kB)\n",
      "Collecting clarabel>=0.5.0 (from cvxpy->fancyimpute)\n",
      "  Downloading clarabel-0.7.1-cp37-abi3-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting scs>=3.0 (from cvxpy->fancyimpute)\n",
      "  Downloading scs-3.2.4.post1-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting pybind11 (from cvxpy->fancyimpute)\n",
      "  Downloading pybind11-2.12.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (21.2.0)\n",
      "Requirement already satisfied: iniconfig in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (21.0)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (1.10.0)\n",
      "Requirement already satisfied: toml in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (0.10.2)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (1.4.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (0.4.4)\n",
      "Collecting qdldl (from osqp>=0.6.2->cvxpy->fancyimpute)\n",
      "  Downloading qdldl-0.1.7.post1-cp39-cp39-win_amd64.whl.metadata (1.8 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -dna (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -qdm (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -dna (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -qdm (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->pytest->fancyimpute) (3.0.4)\n",
      "Downloading cvxopt-1.3.2-cp39-cp39-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 12.8/12.8 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading cvxpy-1.4.2-cp39-cp39-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 1.0/1.0 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading clarabel-0.7.1-cp37-abi3-win_amd64.whl (321 kB)\n",
      "   ---------------------------------------- 321.5/321.5 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading ecos-2.0.13-cp39-cp39-win_amd64.whl (72 kB)\n",
      "   ---------------------------------------- 72.0/72.0 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading osqp-0.6.5-cp39-cp39-win_amd64.whl (293 kB)\n",
      "   ---------------------------------------- 293.1/293.1 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading scs-3.2.4.post1-cp39-cp39-win_amd64.whl (8.4 MB)\n",
      "   ---------------------------------------- 8.4/8.4 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading pybind11-2.12.0-py3-none-any.whl (234 kB)\n",
      "   ---------------------------------------- 235.0/235.0 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading qdldl-0.1.7.post1-cp39-cp39-win_amd64.whl (86 kB)\n",
      "   ---------------------------------------- 86.5/86.5 kB 4.8 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: fancyimpute, knnimpute\n",
      "  Building wheel for fancyimpute (setup.py): started\n",
      "  Building wheel for fancyimpute (setup.py): finished with status 'done'\n",
      "  Created wheel for fancyimpute: filename=fancyimpute-0.7.0-py3-none-any.whl size=29899 sha256=f9374e68944f1de5614701fad032a9656f22445de4a02c574d09fc364e602684\n",
      "  Stored in directory: c:\\users\\kcs\\appdata\\local\\pip\\cache\\wheels\\f9\\fc\\6a\\b0406b906bce293abe23c3b6da5a72637d2d04146ef1125a0b\n",
      "  Building wheel for knnimpute (setup.py): started\n",
      "  Building wheel for knnimpute (setup.py): finished with status 'done'\n",
      "  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11353 sha256=13da45037d37643bda516954dec349590727c8322070cf657b35ed826afdcfc2\n",
      "  Stored in directory: c:\\users\\kcs\\appdata\\local\\pip\\cache\\wheels\\88\\c4\\be\\e232c750d9bc360abf9a5e2cafe0d3e08e3605d2801bb11684\n",
      "Successfully built fancyimpute knnimpute\n",
      "Installing collected packages: pybind11, knnimpute, cvxopt, scs, qdldl, ecos, clarabel, osqp, cvxpy, fancyimpute\n",
      "Successfully installed clarabel-0.7.1 cvxopt-1.3.2 cvxpy-1.4.2 ecos-2.0.13 fancyimpute-0.7.0 knnimpute-0.1.0 osqp-0.6.5 pybind11-2.12.0 qdldl-0.1.7.post1 scs-3.2.4.post1\n"
     ]
    }
   ],
   "source": [
    "pip install fancyimpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import bisect\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "train = pd.read_csv('train.csv').drop(columns=['SAMPLE_ID'])\n",
    "test = pd.read_csv('test.csv').drop(columns=['SAMPLE_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding features: 100%|██████████| 2/2 [00:00<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# datetime 컬럼 처리\n",
    "train['ATA'] = pd.to_datetime(train['ATA'])\n",
    "test['ATA'] = pd.to_datetime(test['ATA'])\n",
    "\n",
    "# datetime을 여러 파생 변수로 변환\n",
    "for df in [train, test]:\n",
    "    df['hour'] = df['ATA'].dt.hour\n",
    "    df['weekday'] = df['ATA'].dt.weekday\n",
    "\n",
    "# datetime 컬럼 제거\n",
    "train.drop(columns=['ATA','ID','SHIPMANAGER','FLAG'], inplace=True)\n",
    "test.drop(columns=['ATA','ID','SHIPMANAGER','FLAG'], inplace=True)\n",
    "\n",
    "# Categorical 컬럼 인코딩\n",
    "categorical_features = ['ARI_CO', 'ARI_PO']\n",
    "encoders = {}\n",
    "\n",
    "for feature in tqdm(categorical_features, desc=\"Encoding features\"): #tqdm? 진행상황 표시 \n",
    "    le = LabelEncoder() # 카테고리 데이터들을 수치형 데이터로 변환\n",
    "    train[feature] = le.fit_transform(train[feature].astype(str))\n",
    "    le_classes_set = set(le.classes_) # 클래스 집합 생성\n",
    "    test[feature] = test[feature].map(lambda s: '-1' if s not in le_classes_set else s)\n",
    "    le_classes = le.classes_.tolist() # 객체 클래스 리스트 생성\n",
    "    bisect.insort_left(le_classes, '-1') # -1을 리스트에 삽입\n",
    "    le.classes_ = np.array(le_classes) \n",
    "    test[feature] = le.transform(test[feature].astype(str))\n",
    "    encoders[feature] = le\n",
    "\n",
    "train = pd.get_dummies(train,columns=['SHIP_TYPE_CATEGORY'])\n",
    "test = pd.get_dummies(test,columns=['SHIP_TYPE_CATEGORY'])\n",
    "# [배 수치항목서 결측치 존재하는 행 제거]\n",
    "train.dropna(subset=['LENGTH'], inplace=True)\n",
    "# BUILT,U_WIND,V_WIND 열 제거\n",
    "train.drop(columns=['BUILT'],axis=1,inplace=True)\n",
    "test.drop(columns=['BUILT'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ARI_CO                               0\n",
       "ARI_PO                               0\n",
       "DIST                                 0\n",
       "BREADTH                              0\n",
       "DEADWEIGHT                           0\n",
       "DEPTH                                0\n",
       "DRAUGHT                              0\n",
       "GT                                   0\n",
       "LENGTH                               0\n",
       "U_WIND                          163688\n",
       "V_WIND                          163688\n",
       "AIR_TEMPERATURE                 164630\n",
       "BN                              163688\n",
       "ATA_LT                               0\n",
       "PORT_SIZE                            0\n",
       "CI_HOUR                              0\n",
       "hour                                 0\n",
       "weekday                              0\n",
       "SHIP_TYPE_CATEGORY_Bulk              0\n",
       "SHIP_TYPE_CATEGORY_Cargo             0\n",
       "SHIP_TYPE_CATEGORY_Container         0\n",
       "SHIP_TYPE_CATEGORY_Tanker            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['WEEKEND'] = train['weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "train.drop(columns = ['weekday'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['WIND_INTENSITY'] = np.sqrt(train['U_WIND']**2 + train['V_WIND']**2)\n",
    "train['U_WIND_SQUARE'] = train['U_WIND'] ** 2\n",
    "train['V_WIND_SQUARE'] = train['V_WIND'] ** 2\n",
    "train['VOLUME'] = train['BREADTH'] * train['LENGTH'] * train['DEPTH']\n",
    "train['WIND_DIRECTION'] = np.arctan2(train['V_WIND'], train['U_WIND']) * (180/np.pi)\n",
    "train['WIND_DIRECTION'] = train['WIND_DIRECTION'].apply(lambda x: x+360 if x < 0 else x)\n",
    "train['WIND_SPEED_DIR'] = train['WIND_INTENSITY'] * train['WIND_DIRECTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Apr 06 04:30:48 PM: Encountered unexpected exception importing solver CVXOPT:\n",
      "ImportError('DLL load failed while importing base: 지정된 모듈을 찾을 수 없습니다.')\n",
      "(CVXPY) Apr 06 04:30:48 PM: Encountered unexpected exception importing solver GLPK:\n",
      "ImportError('DLL load failed while importing base: 지정된 모듈을 찾을 수 없습니다.')\n",
      "(CVXPY) Apr 06 04:30:48 PM: Encountered unexpected exception importing solver GLPK_MI:\n",
      "ImportError('DLL load failed while importing base: 지정된 모듈을 찾을 수 없습니다.')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216 from C header, got 232 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 56.72259273078394\n"
     ]
    }
   ],
   "source": [
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# MICE 모델 생성\n",
    "mice_imputer = IterativeImputer()\n",
    "\n",
    "\n",
    "\n",
    "# 독립 변수들과 종속 변수 설정\n",
    "X = train.drop(columns=['CI_HOUR'])  # 독립 변수들\n",
    "y = train['CI_HOUR']  # 종속 변수\n",
    "\n",
    "X['DIST'] = X['DIST']+1\n",
    "# 로그 스케일링\n",
    "X['DIST'] = np.log(X['DIST'])\n",
    "\n",
    "# train 데이터와 validation 데이터로 나누기 (80% train, 20% validation)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 결측치를 보완하여 새로운 train 데이터 프레임 생성\n",
    "mice_imputer.fit(X_train)\n",
    "\n",
    "# train 데이터에 대해서만 fit_transform을 사용하여 결측치 보완\n",
    "X_train_imputed = mice_imputer.transform(X_train)\n",
    "\n",
    "# validation 데이터의 결측치 보완\n",
    "X_valid_imputed = mice_imputer.transform(X_valid)\n",
    "\n",
    "# 보완된 데이터를 DataFrame으로 변환\n",
    "X_train = pd.DataFrame(X_train_imputed, columns=X.columns)\n",
    "X_valid = pd.DataFrame(X_valid_imputed, columns=X.columns)\n",
    "\n",
    "traindro = X_train.drop(columns = ['DIST'])\n",
    "validdro = X_valid.drop(columns = ['DIST'])\n",
    "\n",
    "traindist = X_train['DIST']\n",
    "validdist = X_valid['DIST']\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "scaler.fit(traindro)\n",
    "\n",
    "cols = traindro.columns\n",
    "\n",
    "scaler.transform(traindro)\n",
    "scaler.transform(validdro)\n",
    "\n",
    "traindro = pd.DataFrame(scaler.transform(traindro), columns = cols)\n",
    "validdro = pd.DataFrame(scaler.transform(validdro), columns = cols)\n",
    "\n",
    "X_train = pd.concat([traindro, traindist], axis=1)\n",
    "X_valid = pd.concat([validdro, validdist], axis=1)\n",
    "\n",
    "\n",
    "# CatBoostRegressor 모델 생성 및 학습\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# validation 데이터에 대한 예측\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "# MAE 계산 및 출력\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "print(\"Validation MAE:\", mae)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
